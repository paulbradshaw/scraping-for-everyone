<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <!-- above lines taken from https://getbootstrap.com/getting-started/ -->
  <title>Scraping for Everyone: example webpages
  </title>
  <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
      <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
      <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
        <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
      <![endif]-->
      <!-- Latest compiled and minified CSS -->
      <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">

      <!-- Optional theme -->
      <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap-theme.min.css" integrity="sha384-rHyoN1iRsVXV4nD0JutlnGaslCJuC7uwjduW9SVrLvRYooPp2bWYgmgJQIXwl/Sp" crossorigin="anonymous">

  </head>
<body>
  <nav class="navbar navbar-inverse navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
      </div>
      <div id="navbar" class="navbar-collapse collapse">



      </div><!--/.navbar-collapse -->
    </div>
  </nav>
  <div class="jumbotron">
    <div class="container">
<h1>Sample pages for the book Scraping for Everyone</h1>
<p>
In the book <em>Scraping for Everyone</em> (first published as <a href="https://leanpub.com/scrapingforjournalists/"><em>Scraping for Journalists</em></a>) I use a number of examples of live webpages that you can use scraping techniques with.
</p>
<p>
Over time, many of these webpages may either change their design or their structure, or disappear altogether, which means that the code explained in the book will no longer work.
</p>
<p>
If that happens, you can use the samples listed below to test that code and see it working. Note that I have only used the raw HTML, so these webpages do not include any images or other resources. However, the scrapers are only concerned with that raw HTML.
</p>
</div>
</div>

<div class="container">
  <!-- Example row of columns -->
  <div class="row">
    <div class="col-md-4">
<p>
  <h2>Scraper 3: Looking for structure in HTML</h2>

  You can find copies of the webpages mentioned in the chapter here:

  <ul>
    <li>
  <a href="webpages/ch3jobs.html">Jobs search results page</a>
  </li>

  </ul>
</div>
  <div class="col-md-4">
<h2>Scraper 6: Structure in URLs - using Open
Refine</h2>

You can find copies of the webpages mentioned in the chapter here:

<ul>
  <li>
<a href="webpages/ch7hospitalresults.htm">Hospital search results page</a>
</li>
<li>
<a href="webpages/ch7hospital1.htm">Hospital detail page</a>
</li>
</ul>
</div>

  <div class="col-md-4">

<h2>Scraper 7: Scraping multiple pages with
‘next’ links using Outwit Hub</h2>

You can find copies of the webpages mentioned in the chapter here:

<ul>
<li>
<a href="webpages/ch8theatre.htm">The state of UK theatre: In numbers</a>
</li>
<li>
<a href="webpages/ch8g4s_jobs.html">Jobs at G4S</a>
</li>
<li>
<a href="webpages/ch8questions.htm">Parliament’s
search page for written questions and answers</a>
</li>
  <li>
<a href="webpages/ch8lords.htm">Register of Lords' Interests</a>
</li>

</ul>
</div>
</div>
<div class="row">
  <div class="col-md-4">
<h2>Scraper 8: Poorly formatted webpages -
solving problems with OutWit</h2>

You can find copies of the webpages mentioned in the chapter here:

<ul>
  <li>
<a href="webpages/ch9consortium.htm">Pathfinder clinical commissioning groups by Strategic Health Authority clusters</a>
</li>
</ul>
</div>
  <div class="col-md-4">
<h2>Scraper 11: Scraping hidden and ‘invisible’ data on a webpage: icons and ‘reveals’</h2>

You can find copies of the webpages mentioned in the chapter here:

<ul>
  <li>
<a href="webpages/ch10oiahe.htm">Office of the Independent Adjudicator: older case studies</a>
</li>
<li>
<a href="webpages/ch10olympicvenues.htm">2012 Olympic and Paralymic venues accessibility information</a>
</li>
  </ul>

  </div>
    <div class="col-md-4">
<h2>Scraper 12: Introduction to Python</h2>

You can find copies of the webpages mentioned in the chapter here:
<ul>
<li>
<a href="https://onlinejournalismblog.com/2016/02/09/how-and-why-to-save-politicians-and-your-own-tweets-before-they-are-deleted/">How to use IFTTT to scrape tweets</a>
</li>
  </ul>

  </div>
</div>
<div class="row">
    <div class="col-md-4">
  <h2>Scraper 17: Scraping a list of pages</h2>

For this chapter I've created five pages, each of which uses the ID code of a school. They are:
<ul>
<li>
<a href="https://paulbradshaw.github.io/scraping-for-everyone/scottishschools/iSchoolid_5237521.html">Abbotswell School</a>
</li>
<li>
<a href="https://paulbradshaw.github.io/scraping-for-everyone/scottishschools/iSchoolid_5234026.html">Braehead School and Nursery Class</a>
</li>
<li>
<a href="https://paulbradshaw.github.io/scraping-for-everyone/scottishschools/iSchoolid_5237629.html">Airyhall School</a>
</li>
<li>
<a href="https://paulbradshaw.github.io/scraping-for-everyone/scottishschools/iSchoolid_5237823.html">Ashley Road School</a>
</li>
<li>
<a href="https://paulbradshaw.github.io/scraping-for-everyone/scottishschools/iSchoolid_5244439.html">Aberdeen Grammar School</a>
</li>
  </ul>

  </div>
    <div class="col-md-4">
  <h2>Scraper 20: Automating database searches (forms)</h2>

You can find copies of the webpages and scrapers mentioned in the chapter here:
<ul>
<li>
<a href="https://web.archive.org/web/20170401124523/http://www.eib.org/projects/loan/list/index">The EIB search page</a>
</li>

<li>
<a href="https://web.archive.org/web/20170401124541/http://www.eib.org/projects/loan/list/index?from=2007&region=1&sector=&to=2012&country=ES">The EIB search results for projects financed 2007-2012, country 'Spain' and region 'European Union'</a>
</li>
<li>
<a href="https://morph.io/paulbradshaw/Mechanize_test">Scraper code: mechanize test</a>
</li>
  </ul>

  </div>
    <div class="col-md-4">
  <h2>Scraper 22: Storing the results of a search</h2>

  You can find copies of the scraper mentioned in the chapter here:
  <ul>
  <li>
  <a href="https://morph.io/paulbradshaw/Lottery_grants">Scraper code: lottery grants (mechanize)</a>
  </li>

  </ul>

  </div>
</div>
  <div class="row">
    <div class="col-md-4">
  <h2>Scraper 26: Scraping CSV files</h2>

  You can find copies of the data and scrapers mentioned in the chapter here:
  <ul>
    <li>
    <a href="https://raw.githubusercontent.com/paulbradshaw/scraping-for-everyone/gh-pages/scraping-csvs/sgmsreportsvcsfreportsvcsfreports201415vcsfreport2014qtr1final.csv">Copy of CSV data for first two scrapers below</a>
    </li>

  <li>
  <a href="https://morph.io/paulbradshaw/birminghamcouncilexpenditure_2nd">Scraper code: first (broken) attempt at scraping CSV</a>
  </li>

  <li>
  <a href="https://morph.io/paulbradshaw/simple_csv_scraper">Scraper code: second (fixed) attempt at scraping CSV</a>
  </li>
  <li>
  <a href="https://raw.githubusercontent.com/paulbradshaw/scraping-for-everyone/gh-pages/scraping-csvs/usopen2016.csv">US Open data for 2016 - CSV (used for multiple scraper below)</a>
  </li>

  <li>
  <a href="https://raw.githubusercontent.com/paulbradshaw/scraping-for-everyone/gh-pages/scraping-csvs/usopen2015.csv">US Open data for 2015 - CSV (used for multiple scraper below)</a>
  </li>

  <li>
  <a href="https://raw.githubusercontent.com/paulbradshaw/scraping-for-everyone/gh-pages/scraping-csvs/usopen2014.csv">US Open data for 2014 - CSV (used for multiple scraper below)</a>
  </li>
  <li>
  <a href="https://morph.io/paulbradshaw/Multi_CSV_scraper">Scraper code: scraping multiple CSVs including column headings</a>
  </li>
  </ul>
</div>
<div class="col-md-4">
<h2>Scraper 27: Scraping Excel spreadsheets part 1</h2>

You can find copies of the data and scrapers mentioned in the chapter here:
<ul>
<li>
<a href="https://github.com/paulbradshaw/XLRD_tutorial_scraperwiki/blob/master/scraper.py">The first scraper code: XLRD_tutorial_scraperwiki</a>
</li>

<li>
<a href="https://github.com/paulbradshaw/scraping-for-everyone/raw/gh-pages/scraping-xls/incometaxrates_1974to1990.xls">XLS file: income tax rates 1974 to 1990</a>
</li>

<li>
<a href="https://github.com/paulbradshaw/scraping-for-everyone/raw/gh-pages/scraping-xls/dailysr-web-file-we-02-12-12.xls">XLS file 2: DailySR – week ending 2 Dec 12.xls (490KB)</a>
</li>

</ul>
</div>
<div class="col-md-4">
<h2>Scraper 28: Scraping Excel spreadsheets part 2</h2>

You can find copies of the data and scrapers mentioned in the chapter here:
<ul>
<li>
<a href="https://github.com/paulbradshaw/XLRD_scraper_sitreps_1sheet/blob/master/scraper.py">The second scraper code: XLRD_scraper_sitreps_1sheet</a>
</li>

<li>
<a href="https://github.com/paulbradshaw/scraping-for-everyone/raw/gh-pages/scraping-xls/dailysr-pub-file-we-11-11-123.xls">XLS file: DailySR – 6 Nov 12 to 11 Nov 12.xls (446KB).</a>
</li>

</ul>
</div>
</div>
<div class="row">
  <div class="col-md-4">
<h2>Scraper 28 continued: Scraping Excel spreadsheets part 3: scraping multiple sheets</h2>

You can find copies of the data and scrapers mentioned in the chapter here:
<ul>
  <li>
  <a href="https://morph.io/paulbradshaw/XLRD_scraper_sitreps">The scraper on Morph.io: XLRD_scraper_sitreps</a>
  </li>

</ul>
</div>
<div class="col-md-4">
<h2>Scraper 28 continued: Scraping Excel spreadsheets part 4: Dealing with dates in spreadsheets</h2>

You can find copies of the data and scrapers mentioned in the chapter here:
<ul>
<li>
<a href="https://morph.io/paulbradshaw/xlrd_sitreps_linkscraper">The scraper on Morph.io: xlrd_sitreps_linkscraper</a>
</li>
<li>
<a href="https://morph.io/paulbradshaw/XLRD_scraper_sitreps_multisheet_keys_multilinks">The scraper on Morph.io: XLRD_scraper_sitreps_multisheet_keys_multilink</a>
</li>
</ul>
</div>
</div>
</body>
</html>
